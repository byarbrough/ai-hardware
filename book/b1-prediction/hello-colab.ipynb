{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byarbrough/ai-hardware/blob/main/book/b1-prediction/hello-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQT6aaoPRBw"
      },
      "source": [
        "# Hello, Colab!\n",
        "\n",
        "## Pre-reading\n",
        "\n",
        "NONE\n",
        "\n",
        "## Objective\n",
        "\n",
        "Quickly explore our Google Colab environment!\n",
        "\n",
        "### Colab Notebook\n",
        "\n",
        "This is just a Jupyter Notebook, intended to be opened in [Google Colab](https://colab.research.google.com/).\n",
        "\n",
        "Jupyter Notebooks mix Markdown and executable Python in the same document.\n",
        "This GitHub Pages website is static, meaning it cannot run code,\n",
        "but you can open this Notebook in Google Cloud and run it for free!\n",
        "\n",
        "#### Open in Colab\n",
        "\n",
        "From this website you can **click the launch button &#x1F680; at the top right of the page.**\n",
        "\n",
        "Otherwise, either:\n",
        "\n",
        "1. Link your GitHub account and browse to this file from within Colab\n",
        "2. Install the [Open in Colab](https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo) Chrome extension\n",
        "3. Change your URL to replace `github.com/` with `githubtocolab.com`\n",
        "4. Download the file and then upload it to Colab\n",
        "\n",
        "## Platform and Hardware\n",
        "\n",
        "First, let's checkout what operating system our Colab instance is using.\n",
        "\n",
        "We'll then step through the hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZMU-Jv_gndl",
        "outputId": "0645008d-05ff-469b-d659-d291f0941afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "Python version: 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "\n",
        "print(platform.platform())\n",
        "\n",
        "import sys\n",
        "\n",
        "print(\"Python version:\", sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWNrCZwhPkM8"
      },
      "source": [
        "### CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EV_kNhrxPok2",
        "outputId": "62dde76e-c45c-41bf-d6ca-7001faaf910b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cores: 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "cpu_cores = os.cpu_count()\n",
        "\n",
        "print(\"Number of cores:\", cpu_cores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCwl61RRPoQd"
      },
      "source": [
        "### GPU\n",
        "\n",
        "We have to enable the GPU first, as described [here](https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=oM_8ELnJq_wd)\n",
        "\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KN34-ZteOu6k",
        "outputId": "919ddd87-4b71-48e5-d6f8-bc9773cc4635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=b9a9869326fc932d6ee16f38cea03ae7f5ecf2153879f27901daa2d3eae09589\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# The % tells the instance to run this bash command inside the virtual environment\n",
        "%pip install GPUtil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4BEFqZROlS_",
        "outputId": "7e475082-d992-4c75-8d3c-525d7a0219b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU RAM Free: 15101MB | Used: 0MB | Util   0% | Total 15360MB\n"
          ]
        }
      ],
      "source": [
        "import GPUtil\n",
        "\n",
        "gpus = GPUtil.getGPUs()\n",
        "for gpu in gpus:\n",
        "    print(\n",
        "        \"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(\n",
        "            gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil * 100, gpu.memoryTotal\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDQ1n4gKP6CV"
      },
      "source": [
        "## TensorFlow\n",
        "\n",
        "Let's confirm that we can import Tensorflow and it can find the GPU.\n",
        "\n",
        "If this doesn't work, see the previous step and enable the GPU in **Edit -> Notebook Settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X41Y4t83QEiM",
        "outputId": "0302dc67-e2ed-415f-b85c-a17dd1895cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Tensorflow version 2.17.0\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Running Tensorflow version\", tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != \"/device:GPU:0\":\n",
        "    raise SystemError(\"GPU device not found\")\n",
        "\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35bLnV6nQVss"
      },
      "source": [
        "### TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a random image and manually places the resulting ops on either the CPU or the GPU to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dblYvbpdQYlH",
        "outputId": "4c3b9c16-c8ad-450f-bce9-f44b28faf49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "7.207722122000007\n",
            "GPU (s):\n",
            "0.2980054869999975\n",
            "GPU speedup over CPU: 24x\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != \"/device:GPU:0\":\n",
        "    print(\n",
        "        \"\\n\\nThis error most likely means that this notebook is not \"\n",
        "        \"configured to use a GPU.  Change this in Notebook Settings via the \"\n",
        "        \"command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n\"\n",
        "    )\n",
        "    raise SystemError(\"GPU device not found\")\n",
        "\n",
        "\n",
        "def cpu():\n",
        "    with tf.device(\"/cpu:0\"):\n",
        "        random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "        net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "        return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "\n",
        "def gpu():\n",
        "    with tf.device(\"/device:GPU:0\"):\n",
        "        random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "        net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "        return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print(\n",
        "    \"Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images \"\n",
        "    \"(batch x height x width x channel). Sum of ten runs.\"\n",
        ")\n",
        "print(\"CPU (s):\")\n",
        "cpu_time = timeit.timeit(\"cpu()\", number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print(\"GPU (s):\")\n",
        "gpu_time = timeit.timeit(\"gpu()\", number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print(\"GPU speedup over CPU: {}x\".format(int(cpu_time / gpu_time)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}